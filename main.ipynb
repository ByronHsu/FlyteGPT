{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¦…ðŸ”— Building Flyte LangChain Bot on Flyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Ingest documents into a queriable format\n",
    "\n",
    "1. load documents (document loader)\n",
    "2. split documents (text splitter)\n",
    "3. create embeddings for documents (text embedding model)\n",
    "4. store the embeddings in a vector store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ingest_data import load_and_split_documents, embed_and_vectorize_documents\n",
    "\n",
    "# step 1 and 2\n",
    "documents = load_and_split_documents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 and 4\n",
    "vectorstore = embed_and_vectorize_documents(documents)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Query relevant documents by the question and send the context to chat model\n",
    "\n",
    "1. get user question\n",
    "2. look up documents in the index relevant to the question\n",
    "3. construct the prompt from the question + relevant doc\n",
    "4. pass the prompt to a model\n",
    "5. get the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from query_documents import start_conversation\n",
    "\n",
    "start_conversation(vectorstore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
